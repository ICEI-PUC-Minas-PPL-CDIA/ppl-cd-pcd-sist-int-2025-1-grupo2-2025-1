{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11705758,"sourceType":"datasetVersion","datasetId":7347485}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc, balanced_accuracy_score, f1_score, precision_recall_curve\nfrom sklearn.calibration import CalibratedClassifierCV\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nimport seaborn as sns\nimport os\n\n# --- Etapa 0: Configuração ---\n# Criar diretório para salvar os gráficos, se não existir\noutput_dir = '/kaggle/working/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# Configurar o estilo dos gráficos para melhor visualização\nplt.style.use('seaborn-v0_8-whitegrid')\nplt.rcParams['figure.figsize'] = (12, 8)\nplt.rcParams['font.size'] = 12\nplt.rcParams['axes.titlesize'] = 16\nplt.rcParams['axes.labelsize'] = 14\n\n# --- Etapa 1: Carregamento e Pré-processamento dos Dados ---\n\n# Carregar o dataset\ntry:\n    df = pd.read_csv('/kaggle/input/dataset-clean/dados_limpos.csv')\n    print(\"Dataset carregado do caminho Kaggle.\")\nexcept FileNotFoundError:\n    try:\n        df = pd.read_csv('dados_limpos.csv') \n        print(\"Dataset carregado localmente.\")\n    except FileNotFoundError:\n        print(\"Arquivo 'dados_limpos.csv' não encontrado no caminho Kaggle nem localmente.\")\n        print(\"Por favor, certifique-se de que o arquivo está no diretório correto ou ajuste o caminho.\")\n        exit()\n\n# Selecionar colunas relevantes - Expandindo para mais features\ncolunas_features = [\n    'Nível de ensino alcançado', \n    'Tempo de experiência na área de dados',\n    'Área de formação acadêmica',  # Nova feature\n    'Nível de senioridade',        # Nova feature\n    'UF onde mora',                # Nova feature\n    'Setor de atuação da empresa'  # Nova feature\n]\ncoluna_target = 'Faixa salarial mensal'\ncolunas_necessarias = colunas_features + [coluna_target]\n\n# Remover linhas com valores ausentes nas colunas cruciais\ndf_limpo = df[colunas_necessarias].copy()\ndf_limpo.dropna(subset=colunas_necessarias, inplace=True)\n\n# --- Etapa 2: Engenharia de Features e Criação da Variável Alvo ---\n\n# Mapeamento ordinal para 'Nível de ensino alcançado'\nnivel_ensino_map = {\n    'Estudante de Graduação': 0,\n    'Graduação/Bacharelado': 1,\n    'Pós-graduação': 2,\n    'Mestrado': 3,\n    'Doutorado ou Phd': 4\n}\ndf_limpo['formacao_academica_encoded'] = df_limpo['Nível de ensino alcançado'].map(nivel_ensino_map)\n\n# Mapeamento ordinal para 'Tempo de experiência na área de dados'\nexperiencia_map = {\n    'Menos de 1 ano': 0,\n    'de 1 a 2 anos': 1,\n    'de 3 a 4 anos': 2,\n    'de 4 a 6 anos': 3,\n    'de 5 a 6 anos': 3, \n    'de 7 a 10 anos': 4,\n    'Mais de 10 anos': 5\n}\ndf_limpo['experiencia_profissional_encoded'] = df_limpo['Tempo de experiência na área de dados'].map(experiencia_map)\n\n# Mapeamento ordinal para 'Nível de senioridade'\nsenioridade_map = {\n    'Júnior': 0,\n    'Pleno': 1,\n    'Sênior': 2\n}\ndf_limpo['senioridade_encoded'] = df_limpo['Nível de senioridade'].map(senioridade_map)\n\n# Mapeamento ordinal para 'Faixa salarial mensal' para criar a variável alvo binária\nsalario_map_ordinal = {\n    'Menos de R$ 1.000/mês': 0,\n    'de R$ 1.001/mês a R$ 2.000/mês': 1,\n    'de R$ 2.001/mês a R$ 3.000/mês': 2,\n    'de R$ 3.001/mês a R$ 4.000/mês': 3,\n    'de R$ 4.001/mês a R$ 6.000/mês': 4,\n    'de R$ 6.001/mês a R$ 8.000/mês': 5,\n    'de R$ 8.001/mês a R$ 12.000/mês': 6,\n    'de R$ 12.001/mês a R$ 16.000/mês': 7,\n    'de R$ 16.001/mês a R$ 20.000/mês': 8,\n    'de R$ 20.001/mês a R$ 25.000/mês': 9,\n    'de R$ 25.001/mês a R$ 30.000/mês': 10,\n    'de R$ 30.001/mês a R$ 40.000/mês': 11,\n    'Acima de R$ 40.001/mês': 12\n}\ndf_limpo['faixa_salarial_encoded'] = df_limpo['Faixa salarial mensal'].map(salario_map_ordinal)\n\n# Criar variável alvo binária: 0 para salários até R$ 8.000 (<=5), 1 para salários acima (>5)\ndf_limpo['salario_alto'] = df_limpo['faixa_salarial_encoded'].apply(lambda x: 1 if x > 5 else 0)\n\n# Codificação one-hot para variáveis categóricas\ndf_encoded = pd.get_dummies(df_limpo, columns=['Área de formação acadêmica', 'UF onde mora', 'Setor de atuação da empresa'])\n\n# Remover NaNs que podem surgir de mapeamentos incompletos\ndf_encoded.dropna(subset=['formacao_academica_encoded', 'experiencia_profissional_encoded', \n                         'senioridade_encoded', 'faixa_salarial_encoded'], inplace=True)\n\n# Selecionar colunas para o modelo (excluindo as originais não codificadas)\nX_columns = ['formacao_academica_encoded', 'experiencia_profissional_encoded', 'senioridade_encoded'] + \\\n           [col for col in df_encoded.columns if col.startswith(('Área de formação acadêmica_', \n                                                               'UF onde mora_', \n                                                               'Setor de atuação da empresa_'))]\nX = df_encoded[X_columns]\ny = df_encoded['salario_alto']\n\n# Verificar se há dados suficientes\nif X.shape[0] < 10 or len(y.unique()) < 2:\n    print(\"Não há dados suficientes ou classes suficientes após o pré-processamento para treinar o modelo.\")\n    print(f\"Tamanho de X: {X.shape}, Classes em y: {y.unique()}\")\n    exit()\n\n# Verificar o balanceamento das classes\nclass_counts = y.value_counts()\nprint(\"\\nDistribuição das classes:\")\nprint(f\"Salário Baixo/Médio (0): {class_counts[0]} ({class_counts[0]/len(y)*100:.2f}%)\")\nprint(f\"Salário Alto (1): {class_counts[1]} ({class_counts[1]/len(y)*100:.2f}%)\")\n\n# --- Etapa 3: Balanceamento dos Dados ---\n\n# Alternativa ao SMOTE: Usar class_weight e sample_weight\n# Calculando os pesos para cada amostra com base na classe\nclass_weights = {0: 1.0, 1: class_counts[0] / class_counts[1]}\nsample_weights = np.array([class_weights[cls] for cls in y])\n\n# Divisão dos dados em treino e teste\nX_train, X_test, y_train, y_test, sample_weights_train, _ = train_test_split(\n    X, y, sample_weights, test_size=0.3, random_state=42, stratify=y\n)\n\nprint(\"\\nTamanho dos conjuntos de dados:\")\nprint(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\nprint(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n\n# --- Etapa 4: Desenvolvimento do Modelo de Machine Learning - Random Forest ---\n\n# Definir a grade de parâmetros para o GridSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [5, 10, 15],\n    'min_samples_leaf': [3, 5, 7],\n    'class_weight': ['balanced', 'balanced_subsample']\n}\n\n# Instanciar o RandomForestClassifier\nrf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n\n# Instanciar o GridSearchCV com balanced_accuracy_score como métrica\nbalanced_acc_scorer = 'balanced_accuracy'  # Usar métrica balanceada em vez de acurácia simples\n\n# Instanciar o GridSearchCV\ngrid_search = GridSearchCV(estimator=rf_base, param_grid=param_grid,\n                          cv=5, n_jobs=-1, verbose=1, scoring=balanced_acc_scorer)\n\nprint(\"Iniciando a busca de hiperparâmetros com GridSearchCV...\")\ngrid_search.fit(X_train, y_train, sample_weight=sample_weights_train)\n\n# Melhor modelo encontrado pelo GridSearchCV\nbest_rf_model = grid_search.best_estimator_\n\nprint(\"\\nMelhores Parâmetros Encontrados pelo GridSearchCV:\")\nprint(grid_search.best_params_)\n\n# --- Etapa 5: Calibração do Modelo ---\n\n# Calibrar as probabilidades do modelo para obter estimativas mais confiáveis\ncalibrated_model = CalibratedClassifierCV(\n    base_estimator=best_rf_model,\n    method='isotonic',  # ou 'sigmoid'\n    cv=5\n)\n\ncalibrated_model.fit(X_train, y_train, sample_weight=sample_weights_train)\n\n# --- Etapa 6: Avaliação com Diferentes Limiares ---\n\n# Previsões com o modelo calibrado\ny_pred_train = calibrated_model.predict(X_train)\ny_pred_proba_test = calibrated_model.predict_proba(X_test)[:, 1]  # Probabilidades para classe positiva\n\n# Testar diferentes limiares\nthresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\nresults = []\n\nprint(\"\\nAvaliação com diferentes limiares de classificação:\")\nfor threshold in thresholds:\n    y_pred_custom = (y_pred_proba_test >= threshold).astype(int)\n    \n    # Calcular métricas\n    acc = accuracy_score(y_test, y_pred_custom)\n    bal_acc = balanced_accuracy_score(y_test, y_pred_custom)\n    f1 = f1_score(y_test, y_pred_custom)\n    \n    # Matriz de confusão\n    tn, fp, fn, tp = confusion_matrix(y_test, y_pred_custom).ravel()\n    \n    # Calcular precisão e recall para cada classe\n    precision_0 = tn / (tn + fn) if (tn + fn) > 0 else 0\n    recall_0 = tn / (tn + fp) if (tn + fp) > 0 else 0\n    precision_1 = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall_1 = tp / (tp + fn) if (tp + fn) > 0 else 0\n    \n    results.append({\n        'threshold': threshold,\n        'accuracy': acc,\n        'balanced_accuracy': bal_acc,\n        'f1_score': f1,\n        'precision_0': precision_0,\n        'recall_0': recall_0,\n        'precision_1': precision_1,\n        'recall_1': recall_1\n    })\n    \n    print(f\"\\nLimiar: {threshold}\")\n    print(f\"Acurácia: {acc:.4f}\")\n    print(f\"Acurácia Balanceada: {bal_acc:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print(\"Matriz de Confusão:\")\n    print(f\"TN: {tn}, FP: {fp}\")\n    print(f\"FN: {fn}, TP: {tp}\")\n    print(f\"Precisão (Classe 0): {precision_0:.4f}, Recall (Classe 0): {recall_0:.4f}\")\n    print(f\"Precisão (Classe 1): {precision_1:.4f}, Recall (Classe 1): {recall_1:.4f}\")\n\n# Encontrar o melhor limiar com base na acurácia balanceada\nbest_threshold_idx = max(range(len(results)), key=lambda i: results[i]['balanced_accuracy'])\nbest_threshold = results[best_threshold_idx]['threshold']\n\nprint(f\"\\nMelhor limiar encontrado: {best_threshold} (Acurácia Balanceada: {results[best_threshold_idx]['balanced_accuracy']:.4f})\")\n\n# Usar o melhor limiar para as predições finais\ny_pred_final = (y_pred_proba_test >= best_threshold).astype(int)\n\n# --- Etapa 7: Avaliação Final do Modelo ---\n\nprint(\"\\nRelatório de Classificação Final (com limiar otimizado):\")\nprint(classification_report(y_test, y_pred_final, target_names=['Salário Baixo/Médio', 'Salário Alto']))\n\n# --- Etapa 8: Geração de Gráficos ---\n\n# 8.1. Matriz de Confusão\ncm = confusion_matrix(y_test, y_pred_final)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n           xticklabels=['Salário Baixo/Médio', 'Salário Alto'],\n           yticklabels=['Salário Baixo/Médio', 'Salário Alto'],\n           annot_kws={\"size\": 14})\nplt.title('Matriz de Confusão (Conjunto de Teste - Limiar Otimizado)', fontsize=16)\nplt.xlabel('Previsto', fontsize=14)\nplt.ylabel('Verdadeiro', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'matriz_confusao_otimizada.png'), bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.2. Curva ROC\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba_test)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(10, 8))\nplt.plot(fpr, tpr, color='darkorange', lw=3, label=f'Curva ROC (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.axvline(x=fpr[np.argmin(np.abs(tpr - best_threshold))], color='green', linestyle='--', \n           label=f'Limiar Ótimo = {best_threshold}')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taxa de Falsos Positivos (FPR)', fontsize=14)\nplt.ylabel('Taxa de Verdadeiros Positivos (TPR)', fontsize=14)\nplt.title('Curva ROC com Limiar Otimizado', fontsize=16)\nplt.legend(loc=\"lower right\", fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'curva_roc_otimizada.png'), bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.3. Curva Precision-Recall\nprecision, recall, thresholds_pr = precision_recall_curve(y_test, y_pred_proba_test)\n\nplt.figure(figsize=(10, 8))\nplt.plot(recall, precision, color='blue', lw=3)\nplt.xlabel('Recall', fontsize=14)\nplt.ylabel('Precision', fontsize=14)\nplt.title('Curva Precision-Recall', fontsize=16)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'precision_recall_curve.png'), bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.4. Importância das Features - MELHORADA\nimportances = best_rf_model.feature_importances_\nfeature_names = X.columns\nindices = np.argsort(importances)[::-1]\n\n# Limitar para as 20 features mais importantes para melhor visualização\nn_features_to_show = min(20, len(indices))\ntop_indices = indices[:n_features_to_show]\n\nplt.figure(figsize=(16, 10))\nplt.title('Importância das 20 Features Mais Relevantes (Random Forest)', fontsize=16)\nplt.barh(range(n_features_to_show), importances[top_indices], align='center', color='#1f77b4')\nplt.yticks(range(n_features_to_show), [feature_names[i] for i in top_indices], fontsize=12)\nplt.xlabel('Importância Relativa', fontsize=14)\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'importancia_features_top20.png'), bbox_inches='tight', dpi=300)\nplt.close()\n\n# Versão interativa para exploração completa de todas as features\nif len(indices) > 20:\n    # Criar um gráfico separado para todas as features, organizado por grupos\n    # Agrupar features por prefixo para melhor organização\n    prefixes = {}\n    for i in indices:\n        feature = feature_names[i]\n        prefix = feature.split('_')[0] if '_' in feature else feature\n        if prefix not in prefixes:\n            prefixes[prefix] = []\n        prefixes[prefix].append((i, importances[i]))\n    \n    # Plotar gráficos separados por grupo\n    for prefix, features in prefixes.items():\n        if len(features) > 0:\n            # Ordenar features por importância\n            features.sort(key=lambda x: x[1], reverse=True)\n            \n            plt.figure(figsize=(12, max(6, len(features) * 0.4)))\n            plt.title(f'Importância das Features: Grupo {prefix}', fontsize=16)\n            plt.barh(range(len(features)), [imp for _, imp in features], align='center', color='#2ca02c')\n            plt.yticks(range(len(features)), [feature_names[i] for i, _ in features], fontsize=11)\n            plt.xlabel('Importância Relativa', fontsize=14)\n            plt.grid(axis='x', linestyle='--', alpha=0.7)\n            plt.tight_layout()\n            plt.savefig(os.path.join(output_dir, f'importancia_features_grupo_{prefix}.png'), \n                       bbox_inches='tight', dpi=300)\n            plt.close()\n\n# 8.5. Distribuição das Probabilidades Preditas\nplt.figure(figsize=(12, 8))\nsns.histplot(y_pred_proba_test, bins=50, kde=True)\nplt.axvline(x=best_threshold, color='red', linestyle='--', linewidth=2,\n           label=f'Limiar Ótimo = {best_threshold}')\nplt.title('Distribuição das Probabilidades Preditas', fontsize=16)\nplt.xlabel('Probabilidade de Salário Alto', fontsize=14)\nplt.ylabel('Contagem', fontsize=14)\nplt.legend(fontsize=12)\nplt.grid(True, linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'distribuicao_probabilidades.png'), bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.6. Visualizar uma árvore do modelo - MELHORADA\nplt.figure(figsize=(24, 18))  # Aumentar significativamente o tamanho\nplot_tree(best_rf_model.estimators_[0], \n          feature_names=X.columns, \n          class_names=['Salário Baixo/Médio', 'Salário Alto'],\n          filled=True, \n          rounded=True, \n          fontsize=12,  # Aumentar o tamanho da fonte\n          max_depth=4)  # Aumentar a profundidade para mostrar mais detalhes\nplt.title('Visualização de uma Árvore do Random Forest', fontsize=20)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'arvore_exemplo_melhorada.png'), \n           bbox_inches='tight', dpi=300)  # Aumentar a resolução\nplt.close()\n\n# Versão simplificada da árvore para melhor interpretabilidade\nplt.figure(figsize=(20, 12))\nplot_tree(best_rf_model.estimators_[0], \n          feature_names=X.columns, \n          class_names=['Salário Baixo/Médio', 'Salário Alto'],\n          filled=True, \n          rounded=True, \n          fontsize=12,\n          max_depth=3)  # Limitar a profundidade para maior clareza\nplt.title('Visualização Simplificada de uma Árvore do Random Forest', fontsize=20)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'arvore_exemplo_simplificada.png'), \n           bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.7. Análise de Interação entre Formação e Experiência - MELHORADA\nplt.figure(figsize=(14, 10))\npivot_table = pd.crosstab(\n    index=df_limpo['formacao_academica_encoded'], \n    columns=df_limpo['experiencia_profissional_encoded'],\n    values=df_limpo['salario_alto'],\n    aggfunc=np.mean\n)\n\n# Renomear índices e colunas para melhor interpretação\nformacao_labels = {v: k for k, v in nivel_ensino_map.items()}\nexperiencia_labels = {v: k for k, v in experiencia_map.items()}\n\npivot_table.index = [formacao_labels.get(i, i) for i in pivot_table.index]\npivot_table.columns = [experiencia_labels.get(i, i) for i in pivot_table.columns]\n\n# Usar uma paleta de cores mais contrastante e adicionar anotações maiores\nsns.heatmap(pivot_table, annot=True, cmap='viridis', fmt='.2f', \n           cbar_kws={'label': 'Probabilidade de Salário Alto'}, \n           annot_kws={\"size\": 12})\nplt.title('Probabilidade de Salário Alto por Formação Acadêmica e Experiência Profissional', fontsize=16)\nplt.xlabel('Tempo de Experiência', fontsize=14)\nplt.ylabel('Nível de Formação', fontsize=14)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'interacao_formacao_experiencia.png'), \n           bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.8. NOVA VISUALIZAÇÃO: Importância das 3 principais features\ntop3_indices = indices[:3]\ntop3_features = [feature_names[i] for i in top3_indices]\ntop3_importances = importances[top3_indices]\n\n# Criar gráfico de barras horizontais para as top 3 features\nplt.figure(figsize=(10, 6))\nplt.title('Top 3 Features Mais Importantes', fontsize=16)\nbars = plt.barh(range(3), top3_importances, align='center', color=['#1f77b4', '#ff7f0e', '#2ca02c'])\nplt.yticks(range(3), top3_features, fontsize=14)\nplt.xlabel('Importância Relativa', fontsize=14)\n\n# Adicionar os valores nas barras\nfor i, v in enumerate(top3_importances):\n    plt.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=12)\n\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'top3_features.png'), bbox_inches='tight', dpi=300)\nplt.close()\n\n# 8.9. NOVA VISUALIZAÇÃO: Gráfico de dispersão para as duas features mais importantes\nif len(indices) >= 2:\n    top2_indices = indices[:2]\n    feature1 = feature_names[top2_indices[0]]\n    feature2 = feature_names[top2_indices[1]]\n    \n    plt.figure(figsize=(12, 10))\n    scatter = plt.scatter(X_test[feature1], X_test[feature2], \n                         c=y_pred_proba_test, cmap='coolwarm', \n                         alpha=0.7, s=100, edgecolors='k')\n    \n    plt.colorbar(scatter, label='Probabilidade de Salário Alto')\n    plt.xlabel(feature1, fontsize=14)\n    plt.ylabel(feature2, fontsize=14)\n    plt.title(f'Relação entre as Duas Features Mais Importantes\\n{feature1} vs {feature2}', fontsize=16)\n    plt.grid(True, linestyle='--', alpha=0.7)\n    plt.tight_layout()\n    plt.savefig(os.path.join(output_dir, 'dispersao_top2_features.png'), bbox_inches='tight', dpi=300)\n    plt.close()\n\nprint(f\"\\nTodos os gráficos foram salvos no diretório: {output_dir}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}