{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11705758,"sourceType":"datasetVersion","datasetId":7347485}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import plot_tree\nimport seaborn as sns\nimport os\n\n# --- Etapa 0: Configuração ---\n# Criar diretório para salvar os gráficos, se não existir\noutput_dir = '/kaggle/working/'\nif not os.path.exists(output_dir):\n    os.makedirs(output_dir)\n\n# --- Etapa 1: Carregamento e Pré-processamento dos Dados ---\n\n# Carregar o dataset\ntry:\n    df = pd.read_csv('/kaggle/input/dataset-clean/dados_limpos.csv')\n    print(\"Dataset carregado do caminho Kaggle.\")\nexcept FileNotFoundError:\n    try:\n        df = pd.read_csv('dados_limpos.csv') \n        print(\"Dataset carregado localmente.\")\n    except FileNotFoundError:\n        print(\"Arquivo 'dados_limpos.csv' não encontrado no caminho Kaggle nem localmente.\")\n        print(\"Por favor, certifique-se de que o arquivo está no diretório correto ou ajuste o caminho.\")\n        exit()\n\n# Selecionar colunas relevantes\ncolunas_features = ['Nível de ensino alcançado', 'Tempo de experiência na área de dados']\ncoluna_target = 'Faixa salarial mensal'\ncolunas_necessarias = colunas_features + [coluna_target]\n\n# Remover linhas com valores ausentes nas colunas cruciais\ndf_limpo = df[colunas_necessarias].copy()\ndf_limpo.dropna(subset=colunas_necessarias, inplace=True)\n\n# --- Etapa 2: Engenharia de Features e Criação da Variável Alvo ---\n\n# Mapeamento ordinal para 'Nível de ensino alcançado'\nnivel_ensino_map = {\n    'Estudante de Graduação': 0,\n    'Graduação/Bacharelado': 1,\n    'Pós-graduação': 2,\n    'Mestrado': 3,\n    'Doutorado ou Phd': 4\n}\ndf_limpo['formacao_academica_encoded'] = df_limpo['Nível de ensino alcançado'].map(nivel_ensino_map)\n\n# Mapeamento ordinal para 'Tempo de experiência na área de dados'\nexperiencia_map = {\n    'Menos de 1 ano': 0,\n    'de 1 a 2 anos': 1,\n    'de 3 a 4 anos': 2,\n    'de 4 a 6 anos': 3,\n    'de 5 a 6 anos': 3, \n    'de 7 a 10 anos': 4,\n    'Mais de 10 anos': 5\n}\ndf_limpo['experiencia_profissional_encoded'] = df_limpo['Tempo de experiência na área de dados'].map(experiencia_map)\n\n\n# Mapeamento ordinal para 'Faixa salarial mensal' para criar a variável alvo binária\nsalario_map_ordinal = {\n    'Menos de R$ 1.000/mês': 0,\n    'de R$ 1.001/mês a R$ 2.000/mês': 1,\n    'de R$ 2.001/mês a R$ 3.000/mês': 2,\n    'de R$ 3.001/mês a R$ 4.000/mês': 3,\n    'de R$ 4.001/mês a R$ 6.000/mês': 4,\n    'de R$ 6.001/mês a R$ 8.000/mês': 5,\n    'de R$ 8.001/mês a R$ 12.000/mês': 6,\n    'de R$ 12.001/mês a R$ 16.000/mês': 7,\n    'de R$ 16.001/mês a R$ 20.000/mês': 8,\n    'de R$ 20.001/mês a R$ 25.000/mês': 9,\n    'de R$ 25.001/mês a R$ 30.000/mês': 10,\n    'de R$ 30.001/mês a R$ 40.000/mês': 11,\n    'Acima de R$ 40.001/mês': 12\n}\ndf_limpo['faixa_salarial_encoded'] = df_limpo['Faixa salarial mensal'].map(salario_map_ordinal)\n\n# Remover NaNs que podem surgir de mapeamentos incompletos\ndf_limpo.dropna(subset=['formacao_academica_encoded',\n                         'experiencia_profissional_encoded',\n                         'faixa_salarial_encoded'], inplace=True)\n\n# Criar variável alvo binária: 0 para salários até R$ 8.000 (<=5), 1 para salários acima (>5)\ndf_limpo['salario_alto'] = df_limpo['faixa_salarial_encoded'].apply(lambda x: 1 if x > 5 else 0)\n\n# Preparar Features (X) e Target (y)\nX = df_limpo[['formacao_academica_encoded', 'experiencia_profissional_encoded']]\ny = df_limpo['salario_alto']\n\n# Verificar se há dados suficientes\nif X.shape[0] < 10 or len(y.unique()) < 2:\n    print(\"Não há dados suficientes ou classes suficientes após o pré-processamento para treinar o modelo.\")\n    print(f\"Tamanho de X: {X.shape}, Classes em y: {y.unique()}\")\n    exit()\n\n# Divisão dos dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\n# --- Etapa 3: Desenvolvimento do Modelo de Machine Learning - Random Forest ---\n\n# Definir a grade de parâmetros para o GridSearchCV\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20],\n    'min_samples_split': [5, 10, 15],\n    'min_samples_leaf': [3, 5, 7],\n    'class_weight': ['balanced_subsample', 'balanced']\n}\n\n# Instanciar o RandomForestClassifier\nrf_base = RandomForestClassifier(random_state=42, n_jobs=-1)\n\n# Instanciar o GridSearchCV\n# cv=3 para ser mais rápido, idealmente cv=5 ou cv=10\ngrid_search = GridSearchCV(estimator=rf_base, param_grid=param_grid,\n                           cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n\nprint(\"Iniciando a busca de hiperparâmetros com GridSearchCV...\")\ngrid_search.fit(X_train, y_train)\n\n# Melhor modelo encontrado pelo GridSearchCV\nbest_rf_model = grid_search.best_estimator_\n\nprint(\"\\nMelhores Parâmetros Encontrados pelo GridSearchCV:\")\nprint(grid_search.best_params_)\n\n# Previsões com o melhor modelo\ny_pred_train = best_rf_model.predict(X_train)\ny_pred_test = best_rf_model.predict(X_test)\ny_pred_proba_test = best_rf_model.predict_proba(X_test)[:, 1] # Probabilidades para ROC\n\n# --- Etapa 4: Avaliação do Modelo ---\naccuracy_train = accuracy_score(y_train, y_pred_train)\naccuracy_test = accuracy_score(y_test, y_pred_test)\n\nprint(f\"\\nAcurácia do Modelo no Conjunto de Treinamento: {accuracy_train:.4f}\")\nprint(f\"Acurácia do Modelo no Conjunto de Teste: {accuracy_test:.4f}\")\nprint(f\"Diferença de Acurácia (Treino - Teste): {accuracy_train - accuracy_test:.4f}\\n\")\n\nprint(\"Relatório de Classificação no Conjunto de Teste:\")\nprint(classification_report(y_test, y_pred_test, target_names=['Salário Baixo/Médio', 'Salário Alto']))\n\nprint(\"\\nParâmetros do Melhor Modelo Random Forest Utilizado:\")\nprint(best_rf_model.get_params())\n\n# --- Etapa 5: Geração de Gráficos ---\n\n# 5.1. Matriz de Confusão\ncm = confusion_matrix(y_test, y_pred_test)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=['Salário Baixo/Médio', 'Salário Alto'],\n            yticklabels=['Salário Baixo/Médio', 'Salário Alto'])\nplt.title('Matriz de Confusão (Conjunto de Teste)')\nplt.xlabel('Previsto')\nplt.ylabel('Verdadeiro')\nplt.savefig(os.path.join(output_dir, 'matriz_confusao.png'), bbox_inches='tight')\n# plt.show() # Comentado para evitar interrupção se rodando em script não interativo\nplt.close() \n\n# 5.2. Exemplo de uma Árvore de Decisão da Floresta\n\n\n\nplt.figure(figsize=(40, 20)) \nplot_tree(best_rf_model.estimators_[0],\n          feature_names=['Nível de Formação (Encoded)', 'Tempo de Experiência (Encoded)'],\n          class_names=['Salário Baixo/Médio', 'Salário Alto'],\n          filled=True,\n          rounded=True,\n          impurity=True,  # Mostra a impureza (Gini)\n          proportion=False, # Mostra contagens absolutas em 'value'\n          fontsize=7,  # Reduzido de 8 para 7 - ajuste conforme necessário\n          max_depth=4) # Mantém a profundidade limitada para visualização\nplt.title('Exemplo de uma Árvore de Decisão do Random Forest (Profundidade limitada para visualização)', fontsize=20) # Aumenta o tamanho da fonte do título\nplt.savefig(os.path.join(output_dir, 'arvore_decisao_exemplo.png'), bbox_inches='tight', dpi=300) # Adiciona dpi para melhor resolução\n# plt.show() # Comente/descomente conforme sua necessidade de visualização interativa\nplt.close() \n\n# 5.3. Importância das Features\nimportances = best_rf_model.feature_importances_\nfeature_names_importances = ['Nível de Formação', 'Tempo de Experiência']\nforest_importances = pd.Series(importances, index=feature_names_importances)\n\nfig, ax = plt.subplots(figsize=(10,6))\nforest_importances.sort_values(ascending=False).plot.bar(ax=ax)\nax.set_title(\"Importância das Features (Random Forest)\")\nax.set_ylabel(\"Redução média de impureza (Gini)\")\nfig.tight_layout()\nplt.savefig(os.path.join(output_dir, 'importancia_features.png'), bbox_inches='tight')\n# plt.show()\nplt.close()\n\n# 5.4. Curva ROC\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba_test)\nroc_auc = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('Taxa de Falsos Positivos (FPR)')\nplt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\nplt.title('Curva ROC (Receiver Operating Characteristic)')\nplt.legend(loc=\"lower right\")\nplt.savefig(os.path.join(output_dir, 'curva_roc.png'), bbox_inches='tight')\n# plt.show()\nplt.close()\n\n# 5.5. Gráfico de Distribuição da Variável Alvo (Salário Alto)\nplt.figure(figsize=(7, 5))\nsns.countplot(x='salario_alto', data=df_limpo, palette='viridis')\nplt.title('Distribuição da Variável Alvo (0: Salário Baixo/Médio, 1: Salário Alto)')\nplt.xlabel('Categoria Salarial')\nplt.ylabel('Contagem')\nplt.xticks([0,1], ['Salário Baixo/Médio (<= R$8k)', 'Salário Alto (> R$8k)'])\nplt.savefig(os.path.join(output_dir, 'distribuicao_target.png'), bbox_inches='tight')\n# plt.show()\nplt.close()\n\n# 5.6. Análise: Nível de Ensino vs. Proporção de Salário Alto\nnivel_ensino_map_inv = {v: k for k, v in nivel_ensino_map.items()}\ndf_limpo['Nivel de ensino (labels)'] = df_limpo['formacao_academica_encoded'].map(nivel_ensino_map_inv)\n\nplt.figure(figsize=(12, 7))\nsns.barplot(\n    x='Nivel de ensino (labels)',\n    y='salario_alto',\n    data=df_limpo,\n    estimator=lambda x: sum(x==1)*100.0/len(x) if len(x) > 0 else 0.0,\n    palette='coolwarm',\n    order=list(nivel_ensino_map.keys()) # Garante a ordem correta das categorias\n)\nplt.title('Proporção de Profissionais com Salário Alto por Nível de Ensino')\nplt.xlabel('Nível de Ensino Alcançado')\nplt.ylabel('Proporção de Salário Alto (%)')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'formacao_vs_salario_alto.png'), bbox_inches='tight')\n# plt.show()\nplt.close()\n\n# 5.7. Análise: Tempo de Experiência vs. Proporção de Salário Alto\nexperiencia_map_inv = {v: k for k, v in experiencia_map.items()}\nordered_experiencia_labels = sorted(experiencia_map, key=experiencia_map.get)\nunique_ordered_experiencia_labels = []\nseen_values = set()\nfor label in ordered_experiencia_labels:\n    encoded_val = experiencia_map[label]\n    if encoded_val not in seen_values:\n        original_label_for_unique_value = next(k for k,v in experiencia_map.items() if v == encoded_val and k in ordered_experiencia_labels)\n        if original_label_for_unique_value not in unique_ordered_experiencia_labels: # Para evitar duplicatas de labels se vários mapeiam para o mesmo valor encodado mas queremos apenas um representante\n             unique_ordered_experiencia_labels.append(original_label_for_unique_value)\n        seen_values.add(encoded_val)\n\n\ndf_limpo['Experiencia (labels)'] = df_limpo['experiencia_profissional_encoded'].map(experiencia_map_inv)\n\nvalid_experiencia_labels_in_df = df_limpo['Experiencia (labels)'].dropna().unique()\nfinal_ordered_experiencia_labels = [lbl for lbl in unique_ordered_experiencia_labels if lbl in valid_experiencia_labels_in_df]\n\n\nplt.figure(figsize=(12, 7))\nsns.barplot(\n    x='Experiencia (labels)',\n    y='salario_alto',\n    data=df_limpo,\n    estimator=lambda x: sum(x==1)*100.0/len(x) if len(x) > 0 else 0.0,\n    palette='coolwarm',\n    order=final_ordered_experiencia_labels \n)\nplt.title('Proporção de Profissionais com Salário Alto por Tempo de Experiência')\nplt.xlabel('Tempo de Experiência na Área de Dados')\nplt.ylabel('Proporção de Salário Alto (%)')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig(os.path.join(output_dir, 'experiencia_vs_salario_alto.png'), bbox_inches='tight')\n# plt.show()\nplt.close()\n\nprint(f\"\\nTodos os gráficos foram salvos no diretório: {output_dir}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-10T20:06:42.294629Z","iopub.execute_input":"2025-05-10T20:06:42.294967Z","iopub.status.idle":"2025-05-10T20:08:38.465152Z","shell.execute_reply.started":"2025-05-10T20:06:42.294938Z","shell.execute_reply":"2025-05-10T20:08:38.463329Z"}},"outputs":[{"name":"stdout","text":"Dataset carregado do caminho Kaggle.\nIniciando a busca de hiperparâmetros com GridSearchCV...\nFitting 3 folds for each of 162 candidates, totalling 486 fits\n\nMelhores Parâmetros Encontrados pelo GridSearchCV:\n{'class_weight': 'balanced_subsample', 'max_depth': None, 'min_samples_leaf': 3, 'min_samples_split': 5, 'n_estimators': 100}\n\nAcurácia do Modelo no Conjunto de Treinamento: 0.7544\nAcurácia do Modelo no Conjunto de Teste: 0.7283\nDiferença de Acurácia (Treino - Teste): 0.0262\n\nRelatório de Classificação no Conjunto de Teste:\n                     precision    recall  f1-score   support\n\nSalário Baixo/Médio       0.84      0.65      0.73       568\n       Salário Alto       0.64      0.84      0.72       422\n\n           accuracy                           0.73       990\n          macro avg       0.74      0.74      0.73       990\n       weighted avg       0.76      0.73      0.73       990\n\n\nParâmetros do Melhor Modelo Random Forest Utilizado:\n{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced_subsample', 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 3, 'min_samples_split': 5, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n\nTodos os gráficos foram salvos no diretório: /kaggle/working/\n","output_type":"stream"}],"execution_count":2}]}